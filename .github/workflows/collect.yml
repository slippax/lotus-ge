name: OSRS Data Collector
on:
  workflow_dispatch: # Manual trigger button
  repository_dispatch: # External trigger via API
    types: [collect-data]

permissions:
  contents: write # Required for git push

jobs:
  collect:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Get fresh Dropbox access token
        run: |
          echo "ðŸ”„ Refreshing Dropbox access token..."

          # Get fresh access token using refresh token
          RESPONSE=$(curl -X POST https://api.dropboxapi.com/oauth2/token \
            -d grant_type=refresh_token \
            -d refresh_token="${{ secrets.DROPBOX_REFRESH_TOKEN }}" \
            -d client_id="${{ secrets.DROPBOX_APP_KEY }}" \
            -d client_secret="${{ secrets.DROPBOX_APP_SECRET }}" \
            --silent)

          # Extract access token from response using Python
          ACCESS_TOKEN=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['access_token'])" 2>/dev/null || echo "")

          if [ -z "$ACCESS_TOKEN" ]; then
            echo "âŒ Failed to refresh Dropbox access token"
            echo "Response: $RESPONSE"
            exit 1
          fi

          echo "âœ… Successfully refreshed Dropbox access token"
          # Store token for use in subsequent steps
          echo "FRESH_DROPBOX_TOKEN=$ACCESS_TOKEN" >> $GITHUB_ENV

      - name: Download existing database
        run: |
          mkdir -p data
          echo "ðŸ”„ Attempting to download existing database from Dropbox..."

          # Try to download existing database from Dropbox with fresh token
          HTTP_CODE=$(curl -X POST https://content.dropboxapi.com/2/files/download \
            --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
            --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\"}" \
            --output data/osrsmarketdata.sqlite \
            --write-out "%{http_code}" \
            --silent)

          if [ "$HTTP_CODE" = "200" ]; then
            echo "âœ… Successfully downloaded existing database from Dropbox"
            ls -la data/osrsmarketdata.sqlite
          else
            echo "âŒ Failed to download database from Dropbox"
            echo "HTTP Status Code: $HTTP_CODE"

            # Get detailed error information
            echo "ðŸ” Attempting to get detailed error information..."
            curl -X POST https://content.dropboxapi.com/2/files/download \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\"}" \
              --output /dev/null \
              --include \
              --silent || true

            echo "ðŸš¨ CRITICAL: Cannot proceed without existing database - this would lose historical data!"
            echo "Please check:"
            echo "1. Dropbox refresh token validity"
            echo "2. Database file exists at /osrsmarketdata.sqlite in Dropbox"
            echo "3. Dropbox API service status"
            exit 1
          fi

      - name: Collect OSRS data
        run: python collect.py

      - name: Upload updated database
        run: |
          echo "ðŸ”„ Uploading updated database back to Dropbox..."

          # Verify database file exists and has reasonable size
          if [ ! -f "data/osrsmarketdata.sqlite" ]; then
            echo "âŒ Database file not found - cannot upload"
            exit 1
          fi

          DB_SIZE=$(stat -f%z data/osrsmarketdata.sqlite 2>/dev/null || stat -c%s data/osrsmarketdata.sqlite 2>/dev/null)
          echo "ðŸ“Š Database size: $DB_SIZE bytes"

          if [ "$DB_SIZE" -lt 1000 ]; then
            echo "âŒ Database file too small ($DB_SIZE bytes) - likely corrupted"
            exit 1
          fi

          # Use chunked upload for large files (>150MB) or regular upload for smaller files
          if [ "$DB_SIZE" -gt 157286400 ]; then
            echo "ðŸ”„ Using chunked upload for large database..."

            # Start upload session
            SESSION_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/start \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Content-Type: application/octet-stream" \
              --data-binary @data/osrsmarketdata.sqlite \
              --silent)

            SESSION_ID=$(echo "$SESSION_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['session_id'])" 2>/dev/null)

            if [ -z "$SESSION_ID" ]; then
              echo "âŒ Failed to start upload session"
              echo "Response: $SESSION_RESPONSE"
              exit 1
            fi

            echo "âœ… Upload session started: $SESSION_ID"

            # Finish upload session
            FINISH_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/finish \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"cursor\": {\"session_id\": \"$SESSION_ID\", \"offset\": $DB_SIZE}, \"commit\": {\"path\": \"/osrsmarketdata.sqlite\", \"mode\": \"overwrite\"}}" \
              --header "Content-Type: application/octet-stream" \
              --write-out "HTTPSTATUS:%{http_code}" \
              --silent)

            # Extract HTTP status code from response
            HTTP_CODE=$(echo "$FINISH_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            RESPONSE_BODY=$(echo "$FINISH_RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')

          else
            echo "ðŸ”„ Using regular upload for smaller database..."

            # Regular upload for smaller files
            UPLOAD_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\", \"mode\": \"overwrite\"}" \
              --header "Content-Type: application/octet-stream" \
              --data-binary @data/osrsmarketdata.sqlite \
              --write-out "HTTPSTATUS:%{http_code}" \
              --silent)

            # Extract HTTP status code from response
            HTTP_CODE=$(echo "$UPLOAD_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            RESPONSE_BODY=$(echo "$UPLOAD_RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')
          fi

          if [ "$HTTP_CODE" = "200" ]; then
            echo "âœ… Successfully uploaded updated database to Dropbox"
            echo "ðŸ“ File info: $(echo "$RESPONSE_BODY" | python3 -c "import sys, json; data=json.load(sys.stdin); print(f\"{data['name']} ({data['size']} bytes)\")" 2>/dev/null || echo "Upload confirmed")"
          else
            echo "âŒ Failed to upload database to Dropbox"
            echo "HTTP Status Code: $HTTP_CODE"
            echo "Response: $RESPONSE_BODY"
            echo "ðŸš¨ WARNING: Database changes not backed up to Dropbox!"
            exit 1
          fi

      - name: Commit and push analysis results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "OSRS Data Collector"

          # Commit analysis results, not the raw database
          git add data/summaries/
          git add data/*.json 2>/dev/null || true
          git add data/*.csv 2>/dev/null || true

          if ! git diff --staged --quiet; then
            git commit -m "Data collection: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            git push
            echo "âœ“ Analysis results committed and pushed"

            # Notify users of instant data update
            curl -X POST "https://ntfy.sh/osrs-ge-lotus-updates" \
              -H "Title: OSRS Market Data Updated" \
              -d "refresh"
          else
            echo "â„¹ No changes to commit"
          fi
