name: OSRS Data Collector
on:
  workflow_dispatch: # Manual trigger button
  repository_dispatch: # External trigger via API
    types: [collect-data]

permissions:
  contents: write # Required for git push

jobs:
  collect:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Get fresh Dropbox access token
        run: |
          echo "üîÑ Refreshing Dropbox access token..."

          # Get fresh access token using refresh token
          RESPONSE=$(curl -X POST https://api.dropboxapi.com/oauth2/token \
            -d grant_type=refresh_token \
            -d refresh_token="${{ secrets.DROPBOX_REFRESH_TOKEN }}" \
            -d client_id="${{ secrets.DROPBOX_APP_KEY }}" \
            -d client_secret="${{ secrets.DROPBOX_APP_SECRET }}" \
            --silent)

          # Extract access token from response using Python
          ACCESS_TOKEN=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['access_token'])" 2>/dev/null || echo "")

          if [ -z "$ACCESS_TOKEN" ]; then
            echo "‚ùå Failed to refresh Dropbox access token"
            echo "Response: $RESPONSE"
            exit 1
          fi

          echo "‚úÖ Successfully refreshed Dropbox access token"
          # Store token for use in subsequent steps
          echo "FRESH_DROPBOX_TOKEN=$ACCESS_TOKEN" >> $GITHUB_ENV

      - name: Download existing database
        run: |
          mkdir -p data
          echo "üîÑ Attempting to download existing database from Dropbox..."

          # Try to download existing database from Dropbox with fresh token
          HTTP_CODE=$(curl -X POST https://content.dropboxapi.com/2/files/download \
            --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
            --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\"}" \
            --output data/osrsmarketdata.sqlite \
            --write-out "%{http_code}" \
            --silent)

          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Successfully downloaded existing database from Dropbox"
            ls -la data/osrsmarketdata.sqlite
          else
            echo "‚ùå Failed to download database from Dropbox"
            echo "HTTP Status Code: $HTTP_CODE"

            # Get detailed error information
            echo "üîç Attempting to get detailed error information..."
            curl -X POST https://content.dropboxapi.com/2/files/download \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\"}" \
              --output /dev/null \
              --include \
              --silent || true

            echo "üö® CRITICAL: Cannot proceed without existing database - this would lose historical data!"
            echo "Please check:"
            echo "1. Dropbox refresh token validity"
            echo "2. Database file exists at /osrsmarketdata.sqlite in Dropbox"
            echo "3. Dropbox API service status"
            exit 1
          fi

      - name: Collect OSRS data
        run: python collect.py

      - name: Upload updated database
        run: |
          echo "üîÑ Uploading updated database back to Dropbox..."

          # Verify database file exists and has reasonable size
          if [ ! -f "data/osrsmarketdata.sqlite" ]; then
            echo "‚ùå Database file not found - cannot upload"
            exit 1
          fi

          DB_SIZE=$(stat -f%z data/osrsmarketdata.sqlite 2>/dev/null || stat -c%s data/osrsmarketdata.sqlite 2>/dev/null)
          echo "üìä Database size: $DB_SIZE bytes"

          if [ "$DB_SIZE" -lt 1000 ]; then
            echo "‚ùå Database file too small ($DB_SIZE bytes) - likely corrupted"
            exit 1
          fi

          # Use chunked upload for large files (>150MB) or regular upload for smaller files
          if [ "$DB_SIZE" -gt 157286400 ]; then
            echo "üîÑ Using chunked upload for large database..."
            echo "üîç Uploading $DB_SIZE bytes in chunks..."

            # Start upload session with first chunk (100MB)
            CHUNK_SIZE=104857600  # 100MB chunks

            echo "üîç Starting session with first chunk..."
            SESSION_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/start \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Content-Type: application/octet-stream" \
              --data-binary @<(head -c $CHUNK_SIZE data/osrsmarketdata.sqlite) \
              --write-out "HTTPSTATUS:%{http_code}" \
              --silent)

            # Extract session info
            SESSION_HTTP_CODE=$(echo "$SESSION_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            SESSION_BODY=$(echo "$SESSION_RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')

            if [ "$SESSION_HTTP_CODE" != "200" ]; then
              echo "‚ùå Failed to start upload session (HTTP $SESSION_HTTP_CODE)"
              echo "Response: $SESSION_BODY"
              exit 1
            fi

            SESSION_ID=$(echo "$SESSION_BODY" | python3 -c "import sys, json; print(json.load(sys.stdin)['session_id'])" 2>/dev/null)

            if [ -z "$SESSION_ID" ]; then
              echo "‚ùå Failed to extract session ID"
              echo "Response: $SESSION_BODY"
              exit 1
            fi

            echo "‚úÖ Upload session started: $SESSION_ID"

            # Upload remaining chunks
            OFFSET=$CHUNK_SIZE
            while [ $OFFSET -lt $DB_SIZE ]; do
              REMAINING=$((DB_SIZE - OFFSET))
              CURRENT_CHUNK_SIZE=$CHUNK_SIZE
              if [ $REMAINING -lt $CHUNK_SIZE ]; then
                CURRENT_CHUNK_SIZE=$REMAINING
              fi

              echo "üîç Uploading chunk at offset $OFFSET (size: $CURRENT_CHUNK_SIZE)"

              APPEND_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/append_v2 \
                --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
                --header "Dropbox-API-Arg: {\"cursor\": {\"session_id\": \"$SESSION_ID\", \"offset\": $OFFSET}}" \
                --header "Content-Type: application/octet-stream" \
                --data-binary @<(tail -c +$((OFFSET + 1)) data/osrsmarketdata.sqlite | head -c $CURRENT_CHUNK_SIZE) \
                --write-out "HTTPSTATUS:%{http_code}" \
                --silent)

              APPEND_HTTP_CODE=$(echo "$APPEND_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)

              if [ "$APPEND_HTTP_CODE" != "200" ]; then
                echo "‚ùå Failed to append chunk (HTTP $APPEND_HTTP_CODE)"
                echo "Response: $APPEND_RESPONSE"
                exit 1
              fi

              OFFSET=$((OFFSET + CURRENT_CHUNK_SIZE))
            done

            echo "‚úÖ All chunks uploaded, finishing session..."

            # Finish upload session
            FINISH_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload_session/finish \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"cursor\": {\"session_id\": \"$SESSION_ID\", \"offset\": $DB_SIZE}, \"commit\": {\"path\": \"/osrsmarketdata.sqlite\", \"mode\": \"overwrite\"}}" \
              --header "Content-Type: application/octet-stream" \
              --write-out "HTTPSTATUS:%{http_code}" \
              --silent)

            # Extract HTTP status code from response
            HTTP_CODE=$(echo "$FINISH_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            RESPONSE_BODY=$(echo "$FINISH_RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')

          else
            echo "üîÑ Using regular upload for smaller database..."

            # Regular upload for smaller files
            UPLOAD_RESPONSE=$(curl -X POST https://content.dropboxapi.com/2/files/upload \
              --header "Authorization: Bearer $FRESH_DROPBOX_TOKEN" \
              --header "Dropbox-API-Arg: {\"path\": \"/osrsmarketdata.sqlite\", \"mode\": \"overwrite\"}" \
              --header "Content-Type: application/octet-stream" \
              --data-binary @data/osrsmarketdata.sqlite \
              --write-out "HTTPSTATUS:%{http_code}" \
              --silent)

            # Extract HTTP status code from response
            HTTP_CODE=$(echo "$UPLOAD_RESPONSE" | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            RESPONSE_BODY=$(echo "$UPLOAD_RESPONSE" | sed 's/HTTPSTATUS:[0-9]*$//')
          fi

          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Successfully uploaded updated database to Dropbox"
            echo "üìÅ File info: $(echo "$RESPONSE_BODY" | python3 -c "import sys, json; data=json.load(sys.stdin); print(f\"{data['name']} ({data['size']} bytes)\")" 2>/dev/null || echo "Upload confirmed")"
          else
            echo "‚ùå Failed to upload database to Dropbox"
            echo "HTTP Status Code: $HTTP_CODE"
            echo "Response: $RESPONSE_BODY"
            echo "üö® WARNING: Database changes not backed up to Dropbox!"
            exit 1
          fi

      - name: Commit and push analysis results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "OSRS Data Collector"

          # Commit analysis results, not the raw database
          git add data/summaries/
          git add data/*.json 2>/dev/null || true
          git add data/*.csv 2>/dev/null || true

          if ! git diff --staged --quiet; then
            git commit -m "Data collection: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            git push
            echo "‚úì Analysis results committed and pushed"

            # Notify users of instant data update
            curl -X POST "https://ntfy.sh/osrs-ge-lotus-updates" \
              -H "Title: OSRS Market Data Updated" \
              -d "refresh"
          else
            echo "‚Ñπ No changes to commit"
          fi
